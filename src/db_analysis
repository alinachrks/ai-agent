from docx import Document
from docx.shared import Pt
import os
import pandas as pd
import time
import random
from datetime import datetime
from sqlalchemy import inspect
import requests
import json

# ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
inspector = inspect(engine)
tables = inspector.get_table_names()

# Ğ¤Ğ°Ğ¹Ğ» Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°
report_filename = "reports_db.docx"
error_log = "error_log.txt"

# API-ĞºĞ»ÑÑ‡ Gemini
GEMINI_API_KEY = GEMINI_API_KEY
url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
headers = {"Content-Type": "application/json"}

# Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ½Ğ° Ğ¾Ğ´Ğ½Ñƒ Ğ¿Ğ°Ñ‡ĞºÑƒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
TABLES_PER_BATCH = 2

# Ğ“ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
GEO_TYPES = {"geometry", "geography", "point", "geom", "coordinates"}

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¸Ğ»Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°
if os.path.exists(report_filename):
    doc = Document(report_filename)
else:
    doc = Document()
    doc.add_heading("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…", 0)
    doc.add_paragraph(f"Ğ”Ğ°Ñ‚Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸
def exponential_backoff(retries, base_delay=2):
    delay = base_delay * (2 ** retries) + random.uniform(0, 0.5)
    time.sleep(delay)

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Markdown-Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Word
def add_markdown_text(doc, text):
    seen_lines = set()  # Ğ¥Ñ€Ğ°Ğ½Ğ¸Ñ‚ ÑƒĞ¶Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
    inside_code_block = False
    code_block_lines = []

    for line in text.split("\n"):
        line = line.strip()
        if not line:
            continue

        # Ğ˜ÑĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼Ğ¸ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸ĞµĞ¼
        if ":" in line:
            parts = line.split(":")
            if len(parts) > 1 and len(parts[0].split()) < 5:  # Ğ•ÑĞ»Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ°Ñ (<= 5 ÑĞ»Ğ¾Ğ²), Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞµÑ‘
                line = parts[1].strip()

        if not line or line in seen_lines:  # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
            continue
        seen_lines.add(line)

        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ĞºĞ¾Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ±Ğ»Ğ¾ĞºĞ¾Ğ²
        if line.startswith("```"):  
            if inside_code_block:
                p = doc.add_paragraph("\n".join(code_block_lines))
                run = p.runs[0]
                run.font.name = "Courier New"
                run.font.size = Pt(10)
                code_block_lines = []
            inside_code_block = not inside_code_block
            continue  

        if inside_code_block:
            code_block_lines.append(line)
            continue

        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ²
        if line.startswith("# "):
            doc.add_heading(line[2:].strip(), level=1)
        elif line.startswith("## "):
            doc.add_heading(line[3:].strip(), level=2)
        elif line.startswith("### "):
            doc.add_heading(line[4:].strip(), level=3)

        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¿Ğ¸ÑĞºĞ¾Ğ²
        elif line.startswith(("- ", "* ")):
            doc.add_paragraph(line[2:].strip(), style="ListBullet")

        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¶Ğ¸Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ ĞºÑƒÑ€ÑĞ¸Ğ²Ğ°
        elif "**" in line or "*" in line:
            p = doc.add_paragraph()
            parts = line.split("**")
            for i, part in enumerate(parts):
                run = p.add_run(part.strip())
                if i % 2 == 1:
                    run.bold = True

            parts = line.split("*")
            for i, part in enumerate(parts):
                run = p.add_run(part.strip())
                if i % 2 == 1:
                    run.italic = True

        # ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚
        else:
            doc.add_paragraph(line)



# ĞŸĞµÑ€ĞµĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ¿Ğ°Ñ‡ĞºĞ°Ğ¼Ğ¸
for i in range(0, len(tables), TABLES_PER_BATCH):
    batch = tables[i:i + TABLES_PER_BATCH]
    print(f"ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ {i + 1} - {i + len(batch)} Ğ¸Ğ· {len(tables)}...")

    for table in batch:
        try:
            safe_table_name = f'"{table}"'
            columns = inspector.get_columns(table)
            column_info = [f"{col['name']} - {col['type']}" for col in columns if str(col['type']).lower() not in GEO_TYPES]
            column_text = "\n".join(column_info)

            # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ³ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            geo_columns = [col['name'] for col in columns if str(col['type']).lower() in GEO_TYPES]
            
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            query = f"SELECT * FROM {safe_table_name} LIMIT 100"
            df = pd.read_sql(query, engine)

            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
            stats_text = ""
            if not df.empty:
                for col in df.columns:
                    if df[col].dtype in ["int64", "float64"]:
                        stats_text += f"- {col}: min={df[col].min()}, max={df[col].max()}, mean={df[col].mean():.2f}\n"
                    elif df[col].dtype == "object":
                        stats_text += f"- {col}: ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹={df[col].nunique()}\n"

            # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            df_sample = df.head(5)
            df_json = df_sample.to_json(orient="records", force_ascii=False)

            # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ³ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            if geo_columns:
                geo_info = "\n".join([f"- `{col}` ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ³ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ" for col in geo_columns])
                stats_text += f"\n**Ğ“ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:**\n{geo_info}"
            
        except Exception as e:
            df_json = "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
            with open(error_log, "a", encoding="utf-8") as log:
                log.write(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ {table}: {str(e)}\n")

        # Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Gemini
        prompt = f"""
        Ğ¢Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ **Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚** Ğ¿Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ `{table}`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ğ¶ĞµÑ‚ **Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ°Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°Ğ¼** Ğ² Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ.  

        ## ğŸ“Š **ĞĞ±Ñ‰Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ**
        - **ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹:** `{table}`
        - **ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸, ĞºĞ°ĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹ Ğ¸Ğ»Ğ¸ ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°).

        ## ğŸ“ˆ **ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹**
        - ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸ **Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ Ğ¸ Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸** Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….
        - ĞšĞ°ĞºĞ¸Ğµ **ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸** Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¸Ğ· ÑÑ‚Ğ¾Ğ¹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹?
        - ĞšĞ°Ğº ÑÑ‚Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ **Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ³Ğ¾Ñ€Ğ¾Ğ´ÑĞºĞ¾Ğ¹ ÑÑ€ĞµĞ´Ñ‹**?

        ## ğŸš¨ **Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…**
        - Ğ’Ñ‹ÑĞ²Ğ¸ **ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹** (Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ´ÑƒĞ±Ğ»Ğ¸, Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ).
        - ĞšĞ°ĞºĞ¸Ğµ **Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ğ¾Ğ²Ğ»Ğ¸ÑÑ‚ÑŒ Ğ½Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·?
        - ĞšĞ°ĞºĞ¸Ğµ **Ñ€Ğ¸ÑĞºĞ¸ Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ** ÑĞ²ÑĞ·Ğ°Ğ½Ñ‹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ¾Ğ¹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹?

        ## ğŸ›  **Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¾Ğ²**
        - ĞšĞ°ĞºĞ¸Ğµ **Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ÑÑ?
        - ĞšĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ **ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚Ñƒ** Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…?
        - ĞšĞ°ĞºĞ¸Ğµ **Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸** Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹?

        ## ğŸŒ **ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ² Ğ³Ğ¾Ñ€Ğ¾Ğ´ÑĞºĞ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞµ**
        - ĞšĞ°ĞºĞ¸Ğµ **Ğ³Ğ¾Ñ€Ğ¾Ğ´ÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸** Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑÑ‚Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…?
        - Ğ’ ĞºĞ°ĞºĞ¸Ñ… **Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ñ… Ğ¸Ğ»Ğ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ…** ÑÑ‚Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹?
        - Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹, **Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸** Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

        ## ğŸ” **Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ñ‹**
        - ĞšĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ **Ñ€Ğ°ÑÑˆĞ¸Ñ€Ğ¸Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ** Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ?
        - ĞšĞ°ĞºĞ¸Ğµ **Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸** Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°?
        - ĞšĞ°ĞºĞ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğµ **Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸** Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ€Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ?

        ---

        â³ **Ğ’Ğ°Ğ¶Ğ½Ğ¾:**
        1. ĞĞµ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞ¹ ÑÑ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ»Ğ¸ JSON!  
        2. ĞÑ„Ğ¾Ñ€Ğ¼Ğ»ÑĞ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ **ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ² Markdown**.  
        3. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ **ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·** Ğ±ĞµĞ· Ğ²Ğ¾Ğ´Ñ‹.  
        """


        data = {"contents": [{"parts": [{"text": prompt}]}]}

        retries = 0
        while retries < 5:
            response = requests.post(url, headers=headers, data=json.dumps(data))
            if response.status_code == 200:
                analysis = response.json()["candidates"][0]["content"]["parts"][0]["text"]
                break
            else:
                retries += 1
                exponential_backoff(retries)
                analysis = f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {response.status_code} - {response.text}"

        doc.add_page_break()
        doc.add_heading(f"ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ {table}", level=1)
        doc.add_heading("Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹", level=2)
        doc.add_paragraph(column_text)
        doc.add_heading("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…", level=2)

        add_markdown_text(doc, analysis)

    doc.save(report_filename)
    print(f"âœ… ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½: {report_filename}")

print(f"ğŸ‰ ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½. Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»: {report_filename}")
